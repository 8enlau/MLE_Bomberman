# Bomberman Agent Repository

This repository contains multiple agents developed to play Bomberman. Below is a detailed description of the structure and purpose of each folder and file.

## Repository Structure

### 1. Agents

- **`agent_code/`**  
  All the agents are stored in this directory.
  1. **`NeuralNetworkBestAgent/`**  
     Contains the best-performing agent that uses a neural network.
  2. **`NeuralNetwork_AgentHistory/`**  
     This folder contains all other agents developed using the neural network approach.

### 2. Neural Network Approach

- **`neural_network/`**  
  This folder contains all the code related to our neural network-based approach. Below is the structure of the folder and the role of its sub-components:

  1. **`Dataset/`**  
     Contains the datasets used for training the neural network agents. Each file in this folder consists of a list of lists:
     - The outer list represents the game rounds.
     - The inner lists represent the game states for each step, stored as dictionaries.

  2. **`GameLogs/` and `agent_code/`**  
     These folders store log files generated by the Bomberman framework during gameplay.

  3. **`create_Datasets/`**  
     Contains a slightly adapted version of the Bomberman framework, stripped of GUI features and `argparse`. This script is used to generate the data stored in the `Dataset/` folder.

  4. **`TRAIN*/`** (e.g., `TRAIN_v1`, `TRAIN_v2`, etc.)  
     These folders store network layouts and training progress for each iteration of agent development.
     - Each folder contains a `networkLayout.py` file, which defines the neural network structure and the function that rewrites game states from a dictionary format into a 17x17 matrix format for the network.

  5. **`trainingHandler.py`**  
     Manages the optimization of the agents. It uses the `main.py` script in `create_Datasets/` to play games, stores them in the `Dataset/` folder, and then optimizes the agent specified in the `config.yaml` file.

  6. **`config.yaml`**  
     Contains essential configurations for training, such as optimization hyperparameters and the agent's name to be optimized.

  7. **`rewards.py`**  
     Defines the reward function used by the neural network agent to evaluate its performance during training.

  8. **`helperFunctions.py`**  
     Includes functions that assist the reward function and other tasks in the neural network approach.

---

